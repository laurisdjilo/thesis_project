{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "DATA_PATH = \"../data/triplet_loss_model_dataset\"\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_parts_features_dataset = pd.read_csv(DATA_PATH+\"/prepared_parts_dataset.csv\", index_col='transformed_mpn')\n",
    "triplets_dataset = pd.read_csv(DATA_PATH+\"/triplets_dataset.csv\")\n",
    "triplets_dataset = triplets_dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = [\n",
    "    'FullCounterfeitData|CounterfeitOverallRisk',\n",
    "    'FullCounterfeitData|ManCounterfeitReportsCount',\n",
    "    'FullCounterfeitData|PlCounterfeitReportsCount',\n",
    "    'FullCounterfeitData|TimeSinceMarketIntroduction',\n",
    "    'LifeCycleData|EstimatedYearsToEOL',\n",
    "    'LifeCycleData|MaximumEstimatedYearsToEOL',\n",
    "    'LifeCycleData|MinimumEstimatedYearsToEOL',\n",
    "    'LifeCycleData|OverallRisk',\n",
    "    'PackageData|Feature>Product Depth:Value',\n",
    "    'ParametricData|Features>Maximum Operating Temperature:Value',\n",
    "    'ParametricData|Features>Minimum Operating Temperature:Value',\n",
    "    'ParametricData|Features>Number of Terminals:Value',\n",
    "    'ParametricData|Features>Product Height:Value',\n",
    "    'ParametricData|Features>Product Length:Value',\n",
    "    'ParametricData|Features>Tolerance:Value',\n",
    "    'RiskData|NumberOfDistributors',\n",
    "    'RiskData|NumberOfOtherSources'\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'EnvironmentalDto|ChinaRoHS|EPUP',\n",
    "    'EnvironmentalDto|ChinaRoHS|PBDEFlag',\n",
    "    'EnvironmentalDto|ChinaRoHS|SourceType',\n",
    "    'EnvironmentalDto|ConflictMineralStatus',\n",
    "    'EnvironmentalDto|EICCMembership',\n",
    "    'EnvironmentalDto|EICCTemplateVersion',\n",
    "    'EnvironmentalDto|Exemption',\n",
    "    'EnvironmentalDto|ExemptionCodes',\n",
    "    'EnvironmentalDto|HalgonFree',\n",
    "    'EnvironmentalDto|RareEarthElementInformation',\n",
    "    'EnvironmentalDto|RoHSVersion',\n",
    "    'EnvironmentalDto|RohsIdentifier',\n",
    "    'EnvironmentalDto|SourceType',\n",
    "    'FullCounterfeitData|HistoricalShortagesInventoryReported',\n",
    "    'FullCounterfeitData|IsPopularPart',\n",
    "    'LifeCycleData|LifeCycleRiskGrade',\n",
    "    'LifeCycleData|PartLifecycleCode',\n",
    "    'PackageData|Feature>Mounting:Value',\n",
    "    'PackageData|Feature>Package/Case:Value',\n",
    "    'ParametricData|Features>Life Cycle:Value',\n",
    "    'ParametricData|Features>Mounting:Value',\n",
    "    'ParametricData|Features>Packaging:Value',\n",
    "    'ParametricData|Features>ROHS:Value',\n",
    "    'ParametricData|Features>Technology:Value',\n",
    "    'ParametricData|Features>Temperature Grade:Value',\n",
    "    'ParametricData|Features>Termination Style:Value',\n",
    "    'ReachData|ReachDto|CASNumber',\n",
    "    'ReachData|ReachDto|ContainsSVHC',\n",
    "    'ReachData|ReachDto|EchaNotification',\n",
    "    'ReachData|ReachDto|ReachStatus',\n",
    "    'ReachData|ReachDto|SourceType',\n",
    "    'RiskData|CrossesPartCategory',\n",
    "    'RiskData|InventoryRisk',\n",
    "    'RiskData|LifecycleRisk',\n",
    "    'RiskData|MultiSourcingRisk',\n",
    "    'RiskData|RohsRisk',\n",
    "    'SummaryData|AECQualified',\n",
    "    'SummaryData|Automotive',\n",
    "    'SummaryData|DoseLevel',\n",
    "    'SummaryData|ECCN',\n",
    "    'SummaryData|ESDClass',\n",
    "    'SummaryData|PartMarking',\n",
    "    'SummaryData|RadHard',\n",
    "    'SummaryData|RoHSVersion',\n",
    "    'SummaryData|UNSPSC',\n",
    "    'SummaryData|USChinaTariffImpact'\n",
    "]\n",
    "\n",
    "TEXTUAL_FEATURES = ['SummaryData|PLName', 'SummaryData|PartDescription']\n",
    "\n",
    "DATE_FEATURES = [\n",
    "    'EnvironmentalDto|ExemptionExpirationDate',\n",
    "    'LifeCycleData|LTBDate',\n",
    "    'ReachData|ReachDto|SVHCDateOfInclusion',\n",
    "    'ReachData|ReachDto|SVHCListVersion',\n",
    "    'SummaryData|IntroductionDate',\n",
    "    'SummaryData|LastCheckDate'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_features = raw_parts_features_dataset.copy()\n",
    "\n",
    "# Numerical Features imputation\n",
    "imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "parts_features[NUMERICAL_FEATURES] = imputer.fit_transform(parts_features[NUMERICAL_FEATURES])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here starts the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_features = parts_features[CATEGORICAL_FEATURES+NUMERICAL_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoders = OrdinalEncoder(dtype=np.int64, handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "numerical_standard_scalers = StandardScaler()\n",
    "\n",
    "ordinal_encoders.fit(X=parts_features[CATEGORICAL_FEATURES])\n",
    "numerical_standard_scalers.fit(X=parts_features[NUMERICAL_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartsDataset(Dataset):\n",
    "    def __init__(self, parts_features: pd.DataFrame, triplets: pd.DataFrame, num_features: list, cat_features: list, text_features: list, date_features: list) -> None:\n",
    "        super(PartsDataset, self).__init__()\n",
    "        self.parts_features = parts_features.copy()\n",
    "        self.triplets = triplets.copy()\n",
    "        self.triplets.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.cat_features = cat_features\n",
    "        self.text_features = text_features\n",
    "        self.date_features = date_features\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        p1_num_features = numerical_standard_scalers.transform(self.parts_features.loc[self.triplets['anchor'][[index]], self.num_features])[0]\n",
    "        p1_cat_features = ordinal_encoders.transform(self.parts_features.loc[self.triplets['anchor'][[index]], self.cat_features])[0]\n",
    "\n",
    "        p2_num_features = numerical_standard_scalers.transform(self.parts_features.loc[self.triplets['positive'][[index]], self.num_features])[0]\n",
    "        p2_cat_features = ordinal_encoders.transform(self.parts_features.loc[self.triplets['positive'][[index]], self.cat_features])[0]\n",
    "\n",
    "        p3_num_features = numerical_standard_scalers.transform(self.parts_features.loc[self.triplets['negative'][[index]], self.num_features])[0]\n",
    "        p3_cat_features = ordinal_encoders.transform(self.parts_features.loc[self.triplets['negative'][[index]], self.cat_features])[0]\n",
    "\n",
    "        return p1_num_features, p1_cat_features, p2_num_features, p2_cat_features, p3_num_features, p3_cat_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartEncoder(torch.nn.Module):\n",
    "    def __init__(self, cat_emb_dims: list, final_part_emb_dim: int):\n",
    "        super(PartEncoder, self).__init__()\n",
    "        self.cat_emb_layers = torch.nn.ModuleList([torch.nn.Embedding(x, y) for x, y in cat_emb_dims])\n",
    "        self.fc1 = torch.nn.Linear(in_features=len(NUMERICAL_FEATURES)+sum([y for x, y in cat_emb_dims]), out_features=100)\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(100)\n",
    "        self.fc2 = torch.nn.Linear(in_features=100, out_features=50)\n",
    "        self.droup_out = torch.nn.Dropout(p=0.2)\n",
    "        self.fc3 = torch.nn.Linear(in_features=50, out_features=final_part_emb_dim)\n",
    "\n",
    "    def forward(self, input_num_data, input_cat_data):\n",
    "        x = [emb_layer(input_cat_data[:, i]) for i, emb_layer in enumerate(self.cat_emb_layers)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = torch.cat([x, input_num_data], 1)\n",
    "        x = torch.nn.functional.relu(self.fc1(x.float()))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = torch.nn.functional.relu(self.fc2(x.float()))\n",
    "        x = self.droup_out(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def calc_euclidean(self, x1, x2):\n",
    "        return (x1 - x2).pow(2).sum(1)\n",
    "    \n",
    "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n",
    "        distance_positive = self.calc_euclidean(anchor, positive)\n",
    "        distance_negative = self.calc_euclidean(anchor, negative)\n",
    "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "\n",
    "        return losses.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_emb_dimensions = parts_features[CATEGORICAL_FEATURES].describe().loc['unique'].apply(lambda x: (x, min(50, ceil(1.6*x**0.56)))).values\n",
    "final_part_emb_dimension = ceil(1.6*parts_features.shape[1]**0.56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplets_dataset, test_triplets_dataset = train_test_split(triplets_dataset, test_size=0.2)\n",
    "train_dataset = PartsDataset(parts_features, train_triplets_dataset, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TEXTUAL_FEATURES, DATE_FEATURES)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_encoder_model = PartEncoder(cat_features_emb_dimensions, final_part_emb_dimension)\n",
    "optimizer = torch.optim.SGD(part_encoder_model.parameters(), lr=0.1, momentum=0.9)\n",
    "criterion = TripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "part_encoder_model.train()\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Epochs\"):\n",
    "    running_loss = []\n",
    "    for step, (p1_num_features, p1_cat_features, p2_num_features, p2_cat_features, p3_num_features, p3_cat_features) in enumerate(tqdm(train_data_loader, desc=\"Training\", leave=False)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        anchor_out = part_encoder_model(p1_num_features, p1_cat_features)\n",
    "        positive_out = part_encoder_model(p2_num_features, p2_cat_features)\n",
    "        negative_out = part_encoder_model(p3_num_features, p3_cat_features)\n",
    "        \n",
    "        loss = criterion(anchor_out, positive_out, negative_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss.append(loss.detach().numpy())\n",
    "    print(\"Epoch: {}/{} - Loss: {:.4f}\".format(epoch+1, EPOCHS, np.mean(running_loss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0c3a8c53b65175ab09cc9e40b16d1ba2ab60bb5c1262ebc7978e53535bf8122"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
